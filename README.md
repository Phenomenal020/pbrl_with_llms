**Project Title**: Leveraging Large Language Models for Enhanced Reinforcement Learning in a Robot-Assisted Bathing Task

---

## Introduction

Preference-based Reinforcement Learning (PbRL) offers a promising alternative to traditional reward engineering by allowing agents to learn from preference feedback rather than explicit reward signals that are often tedious to design. This approach also mitigates the issue of reward hacking, where agents exploit poorly specified rewards to achieve high scores without fulfilling the intended task.

Prior work in PbRL has either relied on human-provided preferences or used Large Language Models (LLMs) in relatively simple environments. This project explores the use of PbRL to address a real-world application: the Physical Robot Care Challenge, which involves robot-assisted bed bathing in assistive care settings.

Investigated are:

* A **rank-based prompting strategy** for structured preferences and **Retrieval-Augmented Generation (RAG)** to enhance the reliability of preferences generated by the LLM.
* A **montage mechanism** for image queries to reduce querying cost while better capturing temporal information, using a start-of-trajectory and an end-of-trajectory image.

**Experiments** were conducted to:

1. Assess the feasibility of using LLM-derived preferences in real-world scenarios.
2. Identify challenges and strategies to improve LLM labeling accuracy.

**Key Findings**:

* There is a considerable gap between performance in well-understood test environments and real-world usage, especially with early-stage sub-optimality.
* Lack of access to ground truth makes evaluation of LLM label quality challenging.
* The cost of frequent LLM queries and significant training resources pose practical limitations.

Nevertheless, the findings suggest that **PbRL guided by LLMs remains a viable approach for real-world deployments**.

---

## Quick Start

This repository contains custom code under the `project_code` directory. To run the full code, follow the steps below:

1. **Set up the environment**

   * Follow the installation guidelines in the official [RCareWorld repository (Physical Robot Care branch)](https://github.com/empriselab/RCareWorld/tree/phy-robo-care).

2. **Download and organise**

   * Clone or download this folder into `RCAREWORLD/project_code`.

3. **Run the code**

   * Navigate to `RCAREWORLD/project_code` and run the command `pip install -r requirements.txt`


### Main Directories

1. **reach\_sponge\_dqn**: Code for the reach-and-sponge subtask using DQN.
2. **reach\_sponge\_ppo**: Code for the reach-and-sponge subtask using PPO (on-policy RL).
3. **scrub\_manikin**: Code for the scrub-manikin subtask.

---

## Acknowledgements

Special thanks to the following projects and repositories for some of the source code and inspiration:

* [**Bpref (Benchmarking Preference-Based Reinforcement)**](https://github.com/rll-research/BPref)
* [**RL-VLM-F (Reinforcement Learning from Vision Language Foundation Model Feedback)**](https://rlvlmf2024.github.io/)
* [**RL-SaLM-F (Online Preference-based RL with Self-augmented Feedback from LLM)**](https://github.com/TU2021/RL-SaLLM-F)
* [**RIME (Robust Preference-based Reinforcement Learning with Noisy Preferences)**](https://github.com/CJReinforce/RIME_ICML2024)


---
