{"n_steps": 10, "num_episodes": 0, "num_episodes_steps": 10, "true reward": -8.37621104800114, "pred reward": 0.261928915977478, "done": true, "truncated": false, "n_collisions": 1, "n_successes": 0, "returns": -3.661661431913105, "Current pose": [[1.5, 0.0, 2.0], [0.0, 0.0, 0.0]]}
{"n_steps": 110, "num_episodes": 1, "num_episodes_steps": 100, "true reward": -7.867011607978819, "pred reward": -0.5462349057197571, "done": false, "truncated": true, "n_collisions": 0, "n_successes": 0, "returns": -15.667103899714682, "Current pose": [[-2.0, 0.0, -1.5], [0.0, 90.0, 0.0]]}
{"n_steps": 126, "num_episodes": 2, "num_episodes_steps": 16, "true reward": -9.251060068375887, "pred reward": 0.2586662769317627, "done": true, "truncated": false, "n_collisions": 1, "n_successes": 0, "returns": -5.96611205343669, "Current pose": [[-2.0, 0.0, 1.0], [0.0, 0.0, 0.0]]}
{"n_steps": 172, "num_episodes": 3, "num_episodes_steps": 46, "true reward": -9.29289005645952, "pred reward": 0.2314571589231491, "done": true, "truncated": false, "n_collisions": 1, "n_successes": 0, "returns": -11.548671154185191, "Current pose": [[1.5, 0.0, 1.5], [0.0, 0.0, 0.0]]}
{"n_steps": 184, "num_episodes": 4, "num_episodes_steps": 12, "true reward": -9.852850291528119, "pred reward": 0.2803085446357727, "done": true, "truncated": false, "n_collisions": 1, "n_successes": 0, "returns": -2.5931819155002342, "Current pose": [[2.0, 0.0, 1.0], [0.0, 0.0, 0.0]]}
{"n_steps": 196, "num_episodes": 5, "num_episodes_steps": 12, "true reward": -9.043153136234048, "pred reward": -0.5946422815322876, "done": true, "truncated": false, "n_collisions": 1, "n_successes": 0, "returns": -7.083086516467865, "Current pose": [[-1.75, 0.0, 0.5], [0.0, 180.0, 0.0]]}
{"n_steps": 203, "num_episodes": 6, "num_episodes_steps": 7, "true reward": -9.428197072710065, "pred reward": -14.574722290039062, "done": true, "truncated": false, "n_collisions": 1, "n_successes": 0, "returns": 0.35909295728658996, "Current pose": [[-1.75, 0.0, 2.5], [0.0, 90.0, 0.0]]}
{"n_steps": 207, "num_episodes": 7, "num_episodes_steps": 4, "true reward": -8.972557295902728, "pred reward": 0.20738248527050018, "done": true, "truncated": false, "n_collisions": 1, "n_successes": 0, "returns": -5.075693844375216, "Current pose": [[-2.0, 0.0, 0.5], [0.0, 90.0, 0.0]]}
{"n_steps": 217, "num_episodes": 8, "num_episodes_steps": 10, "true reward": -8.955093331935437, "pred reward": 0.16803398728370667, "done": true, "truncated": false, "n_collisions": 1, "n_successes": 0, "returns": -4.309911593106856, "Current pose": [[2.0, 0.0, 0.5], [0.0, 270.0, 0.0]]}
{"n_steps": 227, "num_episodes": 9, "num_episodes_steps": 10, "true reward": -10.324808626968302, "pred reward": -0.007157007697969675, "done": true, "truncated": false, "n_collisions": 1, "n_successes": 0, "returns": -3.0759982228277654, "Current pose": [[-1.5, 0.0, 2.0], [0.0, 0.0, 0.0]]}
{"n_steps": 266, "num_episodes": 10, "num_episodes_steps": 39, "true reward": -9.470518492359135, "pred reward": -14.88145637512207, "done": true, "truncated": false, "n_collisions": 1, "n_successes": 0, "returns": -1.9375278481993323, "Current pose": [[-1.75, 0.0, 1.5], [0.0, 180.0, 0.0]]}
{"n_steps": 267, "num_episodes": 11, "num_episodes_steps": 1, "true reward": -10.717131100610125, "pred reward": -0.46029219031333923, "done": false, "truncated": true, "n_collisions": 0, "n_successes": 0, "returns": -10.717131100610125, "Current pose": [[-1.5, 0.0, -0.5], [0.0, 0.0, 0.0]]}
{"n_steps": 272, "num_episodes": 12, "num_episodes_steps": 5, "true reward": -9.24710590361763, "pred reward": -0.5504175424575806, "done": true, "truncated": false, "n_collisions": 1, "n_successes": 0, "returns": -8.742647375427433, "Current pose": [[1.75, 0.0, 0.0], [0.0, 180.0, 0.0]]}
{"n_steps": 277, "num_episodes": 13, "num_episodes_steps": 5, "true reward": -9.190094495068093, "pred reward": 0.2393922507762909, "done": true, "truncated": false, "n_collisions": 1, "n_successes": 0, "returns": -6.494439973085327, "Current pose": [[2.0, 0.0, -0.5], [0.0, 180.0, 0.0]]}
{"n_steps": 286, "num_episodes": 14, "num_episodes_steps": 9, "true reward": -11.087334996194206, "pred reward": -0.34056997299194336, "done": true, "truncated": false, "n_collisions": 1, "n_successes": 0, "returns": -6.907707361508862, "Current pose": [[1.5, 0.0, 0.0], [0.0, 180.0, 0.0]]}
{"n_steps": 386, "num_episodes": 15, "num_episodes_steps": 100, "true reward": -7.779915398691495, "pred reward": 0.08139858394861221, "done": false, "truncated": true, "n_collisions": 0, "n_successes": 0, "returns": -20.49169273695975, "Current pose": [[-1.75, 0.0, -1.0], [0.0, 270.0, 0.0]]}
