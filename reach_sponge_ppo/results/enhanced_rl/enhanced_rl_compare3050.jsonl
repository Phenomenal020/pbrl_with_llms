{"n_steps": 9, "num_episodes": 0, "num_episodes_steps": 9, "true reward": -9.895834975710398, "pred reward": -3.792938709259033, "done": true, "truncated": false, "n_collisions": 1, "n_successes": 0, "returns": -4.518941805882644, "Current pose": [[1.5, 0.0, 2.0], [0.0, 0.0, 0.0]]}
{"n_steps": 99, "num_episodes": 1, "num_episodes_steps": 90, "true reward": -9.31490573825723, "pred reward": -2.708019971847534, "done": true, "truncated": false, "n_collisions": 1, "n_successes": 0, "returns": -9.955538023183308, "Current pose": [[-2.0, 0.0, -1.5], [0.0, 90.0, 0.0]]}
{"n_steps": 107, "num_episodes": 2, "num_episodes_steps": 8, "true reward": -10.437780512196436, "pred reward": 2.1914803981781006, "done": true, "truncated": false, "n_collisions": 1, "n_successes": 0, "returns": -4.928427455103309, "Current pose": [[-2.0, 0.0, 1.0], [0.0, 0.0, 0.0]]}
{"n_steps": 156, "num_episodes": 3, "num_episodes_steps": 49, "true reward": 19.991081394783382, "pred reward": 0.9666997790336609, "done": true, "truncated": false, "n_collisions": 0, "n_successes": 1, "returns": 23.708714111532725, "Current pose": [[1.5, 0.0, 1.5], [0.0, 0.0, 0.0]]}
{"n_steps": 192, "num_episodes": 4, "num_episodes_steps": 36, "true reward": -9.45608618948011, "pred reward": -0.8514787554740906, "done": true, "truncated": false, "n_collisions": 1, "n_successes": 1, "returns": -4.838663896329111, "Current pose": [[2.0, 0.0, 1.0], [0.0, 0.0, 0.0]]}
{"n_steps": 193, "num_episodes": 5, "num_episodes_steps": 1, "true reward": -25.21084131949806, "pred reward": -4.259992599487305, "done": false, "truncated": true, "n_collisions": 0, "n_successes": 1, "returns": -25.21084131949806, "Current pose": [[-1.75, 0.0, 0.5], [0.0, 180.0, 0.0]]}
{"n_steps": 217, "num_episodes": 6, "num_episodes_steps": 24, "true reward": -11.939892589506352, "pred reward": -1.4864445924758911, "done": false, "truncated": true, "n_collisions": 0, "n_successes": 1, "returns": -14.78366963454129, "Current pose": [[-1.75, 0.0, 2.5], [0.0, 90.0, 0.0]]}
{"n_steps": 221, "num_episodes": 7, "num_episodes_steps": 4, "true reward": -8.970059786889541, "pred reward": -3.1196823120117188, "done": true, "truncated": false, "n_collisions": 1, "n_successes": 1, "returns": -5.020995923840074, "Current pose": [[-2.0, 0.0, 0.5], [0.0, 90.0, 0.0]]}
{"n_steps": 225, "num_episodes": 8, "num_episodes_steps": 4, "true reward": -8.876956033261598, "pred reward": -1.2239692211151123, "done": true, "truncated": false, "n_collisions": 1, "n_successes": 1, "returns": -4.625634065927242, "Current pose": [[2.0, 0.0, 0.5], [0.0, 270.0, 0.0]]}
{"n_steps": 232, "num_episodes": 9, "num_episodes_steps": 7, "true reward": -9.421941424706443, "pred reward": -1.6777575016021729, "done": true, "truncated": false, "n_collisions": 1, "n_successes": 1, "returns": -1.7120337237808645, "Current pose": [[-1.5, 0.0, 2.0], [0.0, 0.0, 0.0]]}
{"n_steps": 233, "num_episodes": 10, "num_episodes_steps": 1, "true reward": -12.402785755910216, "pred reward": -1.6953566074371338, "done": true, "truncated": false, "n_collisions": 1, "n_successes": 1, "returns": -12.402785755910216, "Current pose": [[-1.75, 0.0, 1.5], [0.0, 180.0, 0.0]]}
{"n_steps": 238, "num_episodes": 11, "num_episodes_steps": 5, "true reward": -9.609741354215641, "pred reward": -1.6395375728607178, "done": true, "truncated": false, "n_collisions": 1, "n_successes": 1, "returns": -8.493454203343008, "Current pose": [[-1.5, 0.0, -0.5], [0.0, 0.0, 0.0]]}
{"n_steps": 255, "num_episodes": 12, "num_episodes_steps": 17, "true reward": -9.110528627206323, "pred reward": -1.3369603157043457, "done": true, "truncated": false, "n_collisions": 1, "n_successes": 1, "returns": -11.585001801212382, "Current pose": [[1.75, 0.0, 0.0], [0.0, 180.0, 0.0]]}
{"n_steps": 267, "num_episodes": 13, "num_episodes_steps": 12, "true reward": -9.13266993567751, "pred reward": -1.5833786725997925, "done": true, "truncated": false, "n_collisions": 1, "n_successes": 1, "returns": -4.7702225495374675, "Current pose": [[2.0, 0.0, -0.5], [0.0, 180.0, 0.0]]}
{"n_steps": 270, "num_episodes": 14, "num_episodes_steps": 3, "true reward": -9.027015274028393, "pred reward": -2.0954318046569824, "done": true, "truncated": false, "n_collisions": 1, "n_successes": 1, "returns": -7.878082607904979, "Current pose": [[1.5, 0.0, 0.0], [0.0, 180.0, 0.0]]}
{"n_steps": 370, "num_episodes": 15, "num_episodes_steps": 100, "true reward": -7.532253072498296, "pred reward": -0.28341513872146606, "done": false, "truncated": true, "n_collisions": 0, "n_successes": 1, "returns": -19.326263361601413, "Current pose": [[-1.75, 0.0, -1.0], [0.0, 270.0, 0.0]]}
