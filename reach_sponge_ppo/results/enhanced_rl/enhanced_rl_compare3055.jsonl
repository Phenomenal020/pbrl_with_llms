{"n_steps": 9, "num_episodes": 0, "num_episodes_steps": 9, "true reward": -9.329993008846921, "pred reward": 3.670856475830078, "done": true, "truncated": false, "n_collisions": 1, "n_successes": 0, "returns": -2.966659090919343, "Current pose": [[1.5, 0.0, 2.0], [0.0, 0.0, 0.0]]}
{"n_steps": 109, "num_episodes": 1, "num_episodes_steps": 100, "true reward": -8.23633804659358, "pred reward": 0.3413847088813782, "done": false, "truncated": true, "n_collisions": 0, "n_successes": 0, "returns": -16.869677644593825, "Current pose": [[-2.0, 0.0, -1.5], [0.0, 90.0, 0.0]]}
{"n_steps": 128, "num_episodes": 2, "num_episodes_steps": 19, "true reward": -9.083500462138145, "pred reward": 0.6529842615127563, "done": true, "truncated": false, "n_collisions": 1, "n_successes": 0, "returns": -3.766592857708293, "Current pose": [[-2.0, 0.0, 1.0], [0.0, 0.0, 0.0]]}
{"n_steps": 228, "num_episodes": 3, "num_episodes_steps": 100, "true reward": -4.675461941645613, "pred reward": 1.5803775787353516, "done": false, "truncated": true, "n_collisions": 0, "n_successes": 0, "returns": -11.550596291962247, "Current pose": [[1.5, 0.0, 1.5], [0.0, 0.0, 0.0]]}
{"n_steps": 310, "num_episodes": 4, "num_episodes_steps": 82, "true reward": -10.241593166246425, "pred reward": 0.6209079623222351, "done": true, "truncated": false, "n_collisions": 1, "n_successes": 0, "returns": -9.366901394470874, "Current pose": [[2.0, 0.0, 1.0], [0.0, 0.0, 0.0]]}
{"n_steps": 315, "num_episodes": 5, "num_episodes_steps": 5, "true reward": -9.051747178715404, "pred reward": -3.578657627105713, "done": true, "truncated": false, "n_collisions": 1, "n_successes": 0, "returns": -8.779756771215673, "Current pose": [[-1.75, 0.0, 0.5], [0.0, 180.0, 0.0]]}
{"n_steps": 322, "num_episodes": 6, "num_episodes_steps": 7, "true reward": -9.33507924436344, "pred reward": -1.643113136291504, "done": true, "truncated": false, "n_collisions": 1, "n_successes": 0, "returns": 0.476755668391025, "Current pose": [[-1.75, 0.0, 2.5], [0.0, 90.0, 0.0]]}
{"n_steps": 331, "num_episodes": 7, "num_episodes_steps": 9, "true reward": -9.617979404755046, "pred reward": -3.3697071075439453, "done": true, "truncated": false, "n_collisions": 2, "n_successes": 0, "returns": -4.7164520985822795, "Current pose": [[-2.0, 0.0, 0.5], [0.0, 90.0, 0.0]]}
{"n_steps": 338, "num_episodes": 8, "num_episodes_steps": 7, "true reward": -9.821420548176365, "pred reward": 0.01999114267528057, "done": true, "truncated": false, "n_collisions": 1, "n_successes": 0, "returns": -4.744587253757661, "Current pose": [[2.0, 0.0, 0.5], [0.0, 270.0, 0.0]]}
{"n_steps": 376, "num_episodes": 9, "num_episodes_steps": 38, "true reward": -9.809848890330567, "pred reward": -1.6317945718765259, "done": true, "truncated": false, "n_collisions": 1, "n_successes": 0, "returns": -4.755670933186356, "Current pose": [[-1.5, 0.0, 2.0], [0.0, 0.0, 0.0]]}
