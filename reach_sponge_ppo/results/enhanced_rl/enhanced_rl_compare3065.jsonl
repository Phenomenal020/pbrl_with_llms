{"n_steps": 10, "num_episodes": 0, "num_episodes_steps": 10, "true reward": -9.827363359362538, "pred reward": -1.6750566959381104, "done": true, "truncated": false, "n_collisions": 1, "n_successes": 0, "returns": -3.2534452260102267, "Current pose": [[1.5, 0.0, 2.0], [0.0, 0.0, 0.0]]}
{"n_steps": 67, "num_episodes": 1, "num_episodes_steps": 57, "true reward": -12.150006870410552, "pred reward": -1.7543128728866577, "done": false, "truncated": true, "n_collisions": 0, "n_successes": 0, "returns": -26.049453835778372, "Current pose": [[-2.0, 0.0, -1.5], [0.0, 90.0, 0.0]]}
{"n_steps": 119, "num_episodes": 2, "num_episodes_steps": 52, "true reward": -10.157708032759542, "pred reward": -1.0932865142822266, "done": true, "truncated": false, "n_collisions": 1, "n_successes": 0, "returns": -7.963439979078045, "Current pose": [[-2.0, 0.0, 1.0], [0.0, 0.0, 0.0]]}
{"n_steps": 131, "num_episodes": 3, "num_episodes_steps": 12, "true reward": -9.092550678854238, "pred reward": -3.7739791870117188, "done": true, "truncated": false, "n_collisions": 1, "n_successes": 0, "returns": -1.842791393125852, "Current pose": [[1.5, 0.0, 1.5], [0.0, 0.0, 0.0]]}
{"n_steps": 132, "num_episodes": 4, "num_episodes_steps": 1, "true reward": -21.19293020988698, "pred reward": 0.7273707985877991, "done": false, "truncated": true, "n_collisions": 0, "n_successes": 0, "returns": -21.19293020988698, "Current pose": [[2.0, 0.0, 1.0], [0.0, 0.0, 0.0]]}
{"n_steps": 140, "num_episodes": 5, "num_episodes_steps": 8, "true reward": -9.17433092216548, "pred reward": -1.2903727293014526, "done": true, "truncated": false, "n_collisions": 1, "n_successes": 0, "returns": -10.275763334518153, "Current pose": [[-1.75, 0.0, 0.5], [0.0, 180.0, 0.0]]}
{"n_steps": 196, "num_episodes": 6, "num_episodes_steps": 56, "true reward": -9.816663799881983, "pred reward": -1.0948551893234253, "done": true, "truncated": false, "n_collisions": 1, "n_successes": 0, "returns": -4.728342697313006, "Current pose": [[-1.75, 0.0, 2.5], [0.0, 90.0, 0.0]]}
{"n_steps": 197, "num_episodes": 7, "num_episodes_steps": 1, "true reward": -6.537637600820483, "pred reward": -0.2679857313632965, "done": true, "truncated": false, "n_collisions": 2, "n_successes": 0, "returns": -6.537637600820483, "Current pose": [[-2.0, 0.0, 0.5], [0.0, 90.0, 0.0]]}
{"n_steps": 198, "num_episodes": 8, "num_episodes_steps": 1, "true reward": -6.638337919675321, "pred reward": -2.878338575363159, "done": true, "truncated": false, "n_collisions": 1, "n_successes": 0, "returns": -6.638337919675321, "Current pose": [[2.0, 0.0, 0.5], [0.0, 270.0, 0.0]]}
{"n_steps": 199, "num_episodes": 9, "num_episodes_steps": 1, "true reward": -16.340395985910096, "pred reward": -3.5927059650421143, "done": false, "truncated": true, "n_collisions": 0, "n_successes": 0, "returns": -16.340395985910096, "Current pose": [[-1.5, 0.0, 2.0], [0.0, 0.0, 0.0]]}
{"n_steps": 237, "num_episodes": 10, "num_episodes_steps": 38, "true reward": -9.9179424107602, "pred reward": 1.1194922924041748, "done": true, "truncated": false, "n_collisions": 1, "n_successes": 0, "returns": -10.962693673124267, "Current pose": [[-1.75, 0.0, 1.5], [0.0, 180.0, 0.0]]}
{"n_steps": 241, "num_episodes": 11, "num_episodes_steps": 4, "true reward": -9.91943701542221, "pred reward": -0.6567241549491882, "done": true, "truncated": false, "n_collisions": 1, "n_successes": 0, "returns": -8.897210252648573, "Current pose": [[-1.5, 0.0, -0.5], [0.0, 0.0, 0.0]]}
{"n_steps": 328, "num_episodes": 12, "num_episodes_steps": 87, "true reward": -12.176735237556661, "pred reward": -2.1407430171966553, "done": false, "truncated": true, "n_collisions": 0, "n_successes": 0, "returns": -38.843367193887914, "Current pose": [[1.75, 0.0, 0.0], [0.0, 180.0, 0.0]]}
{"n_steps": 356, "num_episodes": 13, "num_episodes_steps": 28, "true reward": -9.134231018814914, "pred reward": 0.035775311291217804, "done": true, "truncated": false, "n_collisions": 1, "n_successes": 0, "returns": -7.234999693540693, "Current pose": [[2.0, 0.0, -0.5], [0.0, 180.0, 0.0]]}
{"n_steps": 359, "num_episodes": 14, "num_episodes_steps": 3, "true reward": -9.444772553852527, "pred reward": -0.6362432241439819, "done": true, "truncated": false, "n_collisions": 1, "n_successes": 0, "returns": -8.756602960505534, "Current pose": [[1.5, 0.0, 0.0], [0.0, 180.0, 0.0]]}
