{"n_steps": 6, "num_episodes": 0, "num_episodes_steps": 6, "true reward": -9.507039131141319, "pred reward": 0.13965103030204773, "done": true, "truncated": false, "n_collisions": 1, "n_successes": 0, "returns": -2.961859487330271, "Current pose": [[1.5, 0.0, 2.0], [0.0, 0.0, 0.0]]}
{"n_steps": 9, "num_episodes": 1, "num_episodes_steps": 3, "true reward": -10.247223122231459, "pred reward": 0.4546607434749603, "done": false, "truncated": true, "n_collisions": 0, "n_successes": 0, "returns": -18.99976817852677, "Current pose": [[-2.0, 0.0, -1.5], [0.0, 90.0, 0.0]]}
{"n_steps": 67, "num_episodes": 2, "num_episodes_steps": 58, "true reward": -10.334922913108281, "pred reward": 0.1389855444431305, "done": true, "truncated": false, "n_collisions": 1, "n_successes": 0, "returns": -9.264354110273004, "Current pose": [[-2.0, 0.0, 1.0], [0.0, 0.0, 0.0]]}
{"n_steps": 92, "num_episodes": 3, "num_episodes_steps": 25, "true reward": 30.06392262990925, "pred reward": 0.34022819995880127, "done": true, "truncated": false, "n_collisions": 0, "n_successes": 1, "returns": 37.88182529705764, "Current pose": [[1.5, 0.0, 1.5], [0.0, 0.0, 0.0]]}
{"n_steps": 169, "num_episodes": 4, "num_episodes_steps": 77, "true reward": -9.796761853950104, "pred reward": 0.3129650056362152, "done": true, "truncated": false, "n_collisions": 1, "n_successes": 1, "returns": -9.38499487907779, "Current pose": [[2.0, 0.0, 1.0], [0.0, 0.0, 0.0]]}
{"n_steps": 175, "num_episodes": 5, "num_episodes_steps": 6, "true reward": -12.128246669432789, "pred reward": -0.3897036910057068, "done": true, "truncated": false, "n_collisions": 1, "n_successes": 1, "returns": -10.075367936567087, "Current pose": [[-1.75, 0.0, 0.5], [0.0, 180.0, 0.0]]}
{"n_steps": 193, "num_episodes": 6, "num_episodes_steps": 18, "true reward": -10.499700968765145, "pred reward": -0.38964030146598816, "done": true, "truncated": false, "n_collisions": 1, "n_successes": 1, "returns": -1.5601169022133128, "Current pose": [[-1.75, 0.0, 2.5], [0.0, 90.0, 0.0]]}
{"n_steps": 200, "num_episodes": 7, "num_episodes_steps": 7, "true reward": -10.455188983477434, "pred reward": -0.6220515966415405, "done": true, "truncated": false, "n_collisions": 1, "n_successes": 1, "returns": -8.742315800375973, "Current pose": [[-2.0, 0.0, 0.5], [0.0, 90.0, 0.0]]}
{"n_steps": 204, "num_episodes": 8, "num_episodes_steps": 4, "true reward": -8.890427596162198, "pred reward": 0.11230622231960297, "done": true, "truncated": false, "n_collisions": 1, "n_successes": 1, "returns": -4.76538100535174, "Current pose": [[2.0, 0.0, 0.5], [0.0, 270.0, 0.0]]}
{"n_steps": 290, "num_episodes": 9, "num_episodes_steps": 86, "true reward": -11.120085376725706, "pred reward": 0.49394339323043823, "done": true, "truncated": false, "n_collisions": 1, "n_successes": 1, "returns": -20.212379953151896, "Current pose": [[-1.5, 0.0, 2.0], [0.0, 0.0, 0.0]]}
{"n_steps": 324, "num_episodes": 10, "num_episodes_steps": 34, "true reward": -10.24997842319787, "pred reward": -0.5965923070907593, "done": true, "truncated": false, "n_collisions": 1, "n_successes": 1, "returns": -2.1590620842330743, "Current pose": [[-1.75, 0.0, 1.5], [0.0, 180.0, 0.0]]}
{"n_steps": 340, "num_episodes": 11, "num_episodes_steps": 16, "true reward": -9.743533499753132, "pred reward": 0.44894108176231384, "done": true, "truncated": false, "n_collisions": 1, "n_successes": 1, "returns": -8.334238735961991, "Current pose": [[-1.5, 0.0, -0.5], [0.0, 0.0, 0.0]]}
{"n_steps": 344, "num_episodes": 12, "num_episodes_steps": 4, "true reward": -9.07938075941445, "pred reward": 0.25955086946487427, "done": true, "truncated": false, "n_collisions": 1, "n_successes": 1, "returns": -7.059355167210786, "Current pose": [[1.75, 0.0, 0.0], [0.0, 180.0, 0.0]]}
{"n_steps": 363, "num_episodes": 13, "num_episodes_steps": 19, "true reward": -9.26363475444506, "pred reward": -0.3774006962776184, "done": true, "truncated": false, "n_collisions": 1, "n_successes": 1, "returns": -10.109042008605586, "Current pose": [[2.0, 0.0, -0.5], [0.0, 180.0, 0.0]]}
{"n_steps": 364, "num_episodes": 14, "num_episodes_steps": 1, "true reward": -11.872806851054005, "pred reward": -0.5446783304214478, "done": true, "truncated": false, "n_collisions": 1, "n_successes": 1, "returns": -11.872806851054005, "Current pose": [[1.5, 0.0, 0.0], [0.0, 180.0, 0.0]]}
{"n_steps": 464, "num_episodes": 15, "num_episodes_steps": 100, "true reward": -7.988274731991176, "pred reward": 0.31335628032684326, "done": false, "truncated": true, "n_collisions": 0, "n_successes": 1, "returns": -20.40889236941964, "Current pose": [[-1.75, 0.0, -1.0], [0.0, 270.0, 0.0]]}
